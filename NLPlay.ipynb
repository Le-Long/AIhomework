{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn to tokenize words, we first have a text to learn the most common words. Here I use the wikitext103 dataset from https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitext = open('C:\\\\Users\\\\TA\\\\Downloads\\\\wiki.train.tokens', encoding = 'utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10780437"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikitext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n = Valkyria Chronicles III = \\n \\n Senj≈ç no Valkyr'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do a simple word tokenization and compute the probability of each words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1827460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext = re.compile(r'[.?!]').sub('_S_', wikitext)\n",
    "words = re.findall(re.compile(r'\\w+'), wikitext)\n",
    "n = len(words)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 113161),\n",
       " ('_S_', 77305),\n",
       " ('of', 56889),\n",
       " ('unk', 54625),\n",
       " ('and', 50603),\n",
       " ('in', 39486),\n",
       " ('to', 39190),\n",
       " ('a', 34250),\n",
       " ('was', 20985),\n",
       " ('The', 17602)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = Counter(words)\n",
    "bow.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0619225591805019"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram = dict(zip(words, [bow[word]/n for word in words]))\n",
    "unigram['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Finding a suitable segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now come to the main part, tokenize a continous alphabetical character string into words with the vocabulary we have. First I try a longest-match-first greedy algorithm called maxmatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmatch(text, desc=False):\n",
    "    '''If you want to take the longest word from left to right, set desc to true. \n",
    "    If you take the longest word from right to left, set desc to false.'''\n",
    "    if not text:\n",
    "        return []\n",
    "    if (desc):\n",
    "        for i in range(len(text),-1,-1):\n",
    "            firstword = text[:i]\n",
    "            remainder = text[i:len(text)]\n",
    "            if firstword in words:\n",
    "                return [firstword] + maxmatch(remainder, desc=True)\n",
    "    else:\n",
    "        for i in range(len(text)+1):\n",
    "            firstword = text[:i]\n",
    "            remainder = text[i:len(text)]\n",
    "            if remainder in words:\n",
    "                return maxmatch(firstword, desc=False) + [remainder]\n",
    "    return [text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with some phrase!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'to', 'school']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxmatch(\"gotoschool\", desc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'as', 't', 'u', 'dent']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxmatch(\"Iamastudent\", desc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'a', 'student']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxmatch(\"Iamastudent\", desc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speed', 'of', 'art']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxmatch(\"speedofart\", desc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'mal', 'land', 'insignificant']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxmatch(\"smallandinsignificant\", desc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-gram Language Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to tokenize words is to accept the bag-of-word assumption and choose the phrase with highest probability. Now we will try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramProb(words):\n",
    "    '''Compute the probility of a word sequence.'''\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "        if word in unigram:\n",
    "            prob *= unigram[word]\n",
    "        else:\n",
    "            prob *= 0\n",
    "            break\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(func):\n",
    "    '''A decorator that kinda saves the results to a cache'''\n",
    "    cache = {}\n",
    "    def fmemo(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = func(*args)\n",
    "        return cache[args]\n",
    "    fmemo.cache = cache\n",
    "    return fmemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo\n",
    "def ngramModel(text, probFunction):\n",
    "    '''A n-gram model for word tokenization'''\n",
    "    if not text:\n",
    "        return []\n",
    "    candidate = [[text[:i+1]] + ngramModel(text[i+1:], probFunction) for i in range(len(text)+1)]\n",
    "    return max(candidate, key=probFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'a', 'student']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('iamastudent', unigramProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small', 'and', 'insignificant']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('smallandinsignificant', unigramProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'urn', 'off', 'the', 'light', 'before', 'going', 'out']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('Turnoffthelightbeforegoingout', unigramProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is pretty good but the model still depends the bag-of-word assumption and new words. How about using bigram with smoothing (we can't use simple smoothing technique like add-k because it can't distinguish likely unknown from unlikely unknown words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1827459"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twowords = list(nltk.bigrams(words))\n",
    "m = len(twowords)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 16991),\n",
       " (('_S_', 'The'), 13635),\n",
       " (('in', 'the'), 10580),\n",
       " (('to', 'the'), 5911),\n",
       " (('unk', 'unk'), 5722),\n",
       " (('_S_', 'In'), 4930),\n",
       " (('unk', '_S_'), 4607),\n",
       " (('unk', 'and'), 4272),\n",
       " (('and', 'the'), 4259),\n",
       " (('on', 'the'), 4194)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = Counter(twowords)\n",
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 3.0096434448050544e-05)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = dict(zip(twowords, [bigrams[twoword]/m for twoword in twowords]))\n",
    "(bigrams['I', 'am'], bigram['I', 'am'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramProbLTR(words):\n",
    "    '''Compute the probility of a word sequence with bigram and stupid back-off from left to right.'''\n",
    "    prob = 1\n",
    "    i = 0\n",
    "    for word in words:\n",
    "            if i == 0: \n",
    "                prev = '_S_'\n",
    "            else:\n",
    "                prev = words[i-1]\n",
    "            if (prev + ' ' + word) in bigram and prev in unigram:\n",
    "                prob *= bigram[prev + ' ' + word]\n",
    "            else:\n",
    "                if word in unigram:\n",
    "                    prob *= unigram[word]*0.4\n",
    "                else:\n",
    "                    prob *= 0\n",
    "                    break\n",
    "            i+=1\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramProbRTL(words):\n",
    "    '''Compute the probility of a word sequence with bigram and stupid back-off from right to left.'''\n",
    "    prob = 1\n",
    "    i = -1\n",
    "    for word in words:\n",
    "            if i == -1: \n",
    "                following = '_S_'\n",
    "            else:\n",
    "                following = words[i+1]\n",
    "            if (word + ' ' + following) in bigram and prev in unigram:\n",
    "                prob *= bigram[word + ' ' + following]\n",
    "            else:\n",
    "                if word in unigram:\n",
    "                    prob *= unigram[word]*0.4\n",
    "                else:\n",
    "                    prob *= 0\n",
    "                    break\n",
    "            i-=1\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small', 'and', 'insignificant']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('smallandinsignificant', bigramProbLTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Would', 'you', 'like', 'a', 'cup', 'of', 'tea']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('Wouldyoulikeacupoftea',bigramProbRTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'dry',\n",
       " 'bare',\n",
       " 'sandy',\n",
       " 'hole',\n",
       " 'with',\n",
       " 'nothing',\n",
       " 'in',\n",
       " 'it',\n",
       " 'to',\n",
       " 'sit',\n",
       " 'down',\n",
       " 'on',\n",
       " 'or',\n",
       " 'to',\n",
       " 'eat']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('adrybaresandyholewithnothinginittositdownonortoeat', bigramProbRTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Smoothing with NLTK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram model seems better than unigram, but still not really good because we still can't handle oov words. We can do some smoothing (Katz backoff, Kneser-Ney,...) to have better results. For example, now I will use nltk to make a bigram model without and with Kneser-Ney smoothing and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 2 ngram orders and 3654919 ngrams>\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm import NgramCounter, Vocabulary, MLE, KneserNeyInterpolated\n",
    "newVocab = Vocabulary(bow)\n",
    "count = NgramCounter([list((word,) for word in words) + list(nltk.bigrams(words))])\n",
    "simpleModel = MLE(2, vocabulary=newVocab, counter=count)\n",
    "print(simpleModel.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newProb(words):\n",
    "    '''Another way to compute the log probability of a word sequence with bigram.'''\n",
    "    logprob = 0\n",
    "    bigramText = [('_S_', words[0])] + list(nltk.bigrams(words))\n",
    "    for ngram in bigramText:\n",
    "        logprob += simpleModel.logscore(ngram[0], [ngram[1]])\n",
    "    return logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'to', 'school']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('gotoschool', newProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'p', 'e', 'e', 'd', 'of', 'art']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('speedofart', newProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothedModel = KneserNeyInterpolated(2, vocabulary=newVocab, counter=count)\n",
    "len(smoothedModel.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothedProb(words):\n",
    "    '''Compute the log probability of a word sequence with Kneser-Ney Interpolated.'''\n",
    "    logprob = 0\n",
    "    bigramText = [('_S_', words[0])] + list(nltk.bigrams(words))\n",
    "    for ngram in bigramText:\n",
    "        logprob += smoothedModel.logscore(ngram[0], [ngram[1]])\n",
    "    return logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gotoschool']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramModel('gotoschool', smoothedProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.017895817356235"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothedProb(['gotoschool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.304866550884615"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothedProb(['go', 'to', 'school'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using nltk to make a n-gram model with Kneser-Ney smoothing leads to a very bad result. Maybe there's something wrong with my code, but for now we only have good enough results from unigram and bigram model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate precisely each algorithm, we can use a test set. But how to use it efficiently will take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255018"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = open('C:\\\\Users\\\\TA\\\\Downloads\\\\wiki.test.tokens', encoding = 'utf8').read()\n",
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9668"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = re.split(r'[.?!\\n]', testset)\n",
    "tests = [sentences for sentences in tests if len(sentences) > 30]\n",
    "len(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testset has about 10000 sentences, that's a lot. We can test by running the model with the first 1000 sentences and getting the number of sentences that they guess right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(tests, otherParam):\n",
    "    \"Try segmenter on tests; report failures; return fraction correct.\"\n",
    "    return sum([test_one_sentence(test, otherParam) \n",
    "               for test in tests]), len(tests)\n",
    "\n",
    "def test_one_sentence(test, otherParam):\n",
    "    words = re.findall(re.compile(r'\\w+'), test)\n",
    "    result = ngramModel(''.join(words), otherParam)\n",
    "    correct = (result == words)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862, 1000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(tests[:1000], unigramProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(861, 1000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(tests[:1000], bigramProbRTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(861, 1000)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(tests[:1000], bigramProbLTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the unigram model have a better result than the bigram model. Look like a simple model with enough data is good enough for segmentation task. Of course this still have quite a lot of wrong assumption, but the unigram model is still the best model we have for now. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
